<!doctypehtml><html lang=en><meta http-equiv=Content-Type content="text/html; charset=UTF-8"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Klaus Herrmann (Ph.D.)</title><link rel=stylesheet href=index.css><script defer src=index.js></script><header><div class=topWrapperContainer><div class=box id=avatarContainer><img src=KlausHerrmann.jpg height=150px width=150px id=avatar></div><div class=box id=textContainer><div class=box id=topRowContainer><ul id=topUL><li class=topulItem><a href=#top>Home</a><li class=topulItem><a href=#researchInterests>Research interests</a><li class=topulItem><a href=#publications>Publications</a><li class=topulItem><a href=#talks>Talks</a><li class=topulItem><a href=#teaching>Teaching</a><li class=topulItem><a href=#software>Software</a><li><h2 id=hamburger style=font-size:30px;cursor:pointer onclick=openNav()>‚ò∞</h2></ul></div><div class=box id=bottomRowContainer><h2 id=topName>Klaus Herrmann</h2><p id=topTitle>Professor at Universit√© de Sherbrooke - Klaus - he/him</div></div></div><div id=myNav class=overlay><a href=javascript:void(0) class=closebtn onclick=closeNav()>√ó</a><div class=overlay-content><a href=#top onclick=closeNav()>About</a> <a href=#researchInterests onclick=closeNav()>Research Interests</a> <a href=#publications onclick=closeNav()>Publications</a> <a href=#talks onclick=closeNav()>Talks</a> <a href=#teaching onclick=closeNav()>Teaching</a> <a href=#software onclick=closeNav()>Software</a></div></div></header><div class=row><div class=logo><a href=https://orcid.org/0000-0002-8044-5717><img class=svgImg src=ORCIDiD_iconvector.svg></a><p class=svgText>0000-0002<br>8044-5717</div><div class=logo><a href=https://github.com/KlausHerrmann><img class=svgImg src=reshot-icon-github-NY46M9DGFU.svg></a><p class=svgText>Github</div><div class=logo><a href="mailto: klaus.herrmann@usherbrooke.com"><img class=svgImg src=reshot-icon-letter-L8T6A2FUKX-29286.svg></a><p class=svgText>EMail</div><div class=logo><a href="https://www.openstreetmap.org/#map=19/45.38082/-71.92656"><img class=svgImg src=reshot-icon-map-marker-KS456ZT2P3.svg></a><p class=svgText>D3-1027-7</div></div><div id=aboutRow><p id=address class=pAbout><address>Prof. Klaus Herrmann<br>Department of Mathematics<br>Faculty of science<br>Universit√© de Sherbrooke<br>2500, boul. de l'Universit√©<br>Sherbrooke (Qu√©bec)<br>Canada J1K 2R1<br><br>Office: D3-1027-7</address><p><p id=about class=pAbout><a href=https://www.usherbrooke.ca/mathematiques/nous-joindre/personnel/corps-professoral/professeurs/klaus-herrmann>I'm an assistant professor</a>¬†at the¬†<a href=https://www.usherbrooke.ca/mathematiques/ >Department of mathematics</a>, Faculty of science of the¬†<a href=https://www.usherbrooke.ca/ >Universit√© de Sherbrooke</a>¬†in Sherbrooke, Canada. My research interests are centered around dependence concepts in statistics and probability theory. Specific topics include copula-induced dependence structures, the aggregation of dependent random variables, extreme value theory and multivariate risk measures, with application to portfolio selection and quantitative risk management. Numerical computations of joint probabilities and the evaluation of joint distribution functions is also one of my ongoing research topics.</div><section class=type1><div class=wave><svg id=waveResearchInterests class="svg-2 hidden"data-name="Layer 1"xmlns=http://www.w3.org/2000/svg viewBox="0 0 1200 120"preserveAspectRatio=none><path id=waveResearchInterestsPath d="M0 1200 V60 Q 400 60 400 60 T800 60 T1200 60V1200 z"class=shape-fill-type1></path></svg></div><h1 id=researchInterests>Research Interests</h1><h2>Dependence Modeling</h2><div class=researchInterestBlock><p>Random outcomes are typially not studied in isolation. Instead, it is often natural to consider several random variables at the same time to describe a problem of interest. The central question is then how to account for the interactions between these individual (random) components. In this context, coupling functions called copulas have been succesfully used to describe and study dependence between reandom variables<span id=dotsCopula>...</span><span class=readMore id=moreCopula>.<br>Consider a random vector <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mstyle mathvariant=bold><mi>ùêó</mi></mstyle><mo>=</mo><mo stretchy=false form=prefix>(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>X</mi><mi>d</mi></msub><mo stretchy=false form=postfix>)</mo></mrow><annotation encoding=application/x-tex>\mathbf{X}= (X_1,...,X_d)</annotation></semantics></math> with joint cumulative distribution function <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mo>:</mo><msup><mstyle mathvariant=double-struck><mi>‚Ñù</mi></mstyle><mi>d</mi></msup><mo>‚Üí</mo><mo stretchy=false form=prefix>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=false form=postfix>]</mo><mo>,</mo><mo stretchy=false form=prefix>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>x</mi><mi>d</mi></msub><mo stretchy=false form=postfix>)</mo><mo>‚Ü¶</mo><mi>H</mi><mo stretchy=false form=prefix>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>x</mi><mi>d</mi></msub><mo stretchy=false form=postfix>)</mo><mo>:=</mo><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mo stretchy=false form=prefix>(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>‚â§</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>X</mi><mi>d</mi></msub><mo>‚â§</mo><msub><mi>x</mi><mi>d</mi></msub><mo stretchy=false form=postfix>)</mo><mi>.</mi></mrow><annotation encoding=application/x-tex>H \colon \mathbb{R}^d \to [0,1], (x_1,...,x_d) \mapsto H(x_1,...,x_d) := \mathbb{P}(X_1\leq x_1,...,X_d\leq x_d).</annotation></semantics></math> While <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>H</mi><annotation encoding=application/x-tex>H</annotation></semantics></math> contains all distributional information of <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mstyle mathvariant=bold><mi>ùêó</mi></mstyle><annotation encoding=application/x-tex>\mathbf{X}</annotation></semantics></math>, this information is all tangled together in a one-shot representation. Copulas can be used to disentangle the information contained in the marginal distribution functions <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>F</mi><mi>i</mi></msub><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>:=</mo><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mo stretchy=false form=prefix>(</mo><msub><mi>X</mi><mi>i</mi></msub><mo>‚â§</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo></mrow><annotation encoding=application/x-tex>F_i(x):=\mathbb{P}(X_i\leq x)</annotation></semantics></math>, <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mn>1</mn><mo>‚â§</mo><mi>i</mi><mo>‚â§</mo><mi>d</mi></mrow><annotation encoding=application/x-tex>1\leq i\leq d</annotation></semantics></math>, from the interactions between <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>X</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>X_1,...,X_d</annotation></semantics></math>. Specifically, Sklar‚Äôs representation theorem tells us that <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>H</mi><annotation encoding=application/x-tex>H</annotation></semantics></math> can be expressed as <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>H</mi><mo stretchy=false form=prefix>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>x</mi><mi>d</mi></msub><mo stretchy=false form=postfix>)</mo><mo>=</mo><mi>C</mi><mo stretchy=false form=prefix>(</mo><msub><mi>F</mi><mn>1</mn></msub><mo stretchy=false form=prefix>(</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=false form=postfix>)</mo><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>F</mi><mi>d</mi></msub><mo stretchy=false form=prefix>(</mo><msub><mi>x</mi><mi>d</mi></msub><mo stretchy=false form=postfix>)</mo><mo stretchy=false form=postfix>)</mo><mo>,</mo></mrow><annotation encoding=application/x-tex>\label{eq_Sklar} H(x_1,...,x_d) = C(F_1(x_1),\dots,F_d(x_d)),</annotation></semantics></math> where <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>C</mi><mo>:</mo><mo stretchy=false form=prefix>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><msup><mo stretchy=false form=postfix>]</mo><mi>d</mi></msup><mo>‚Üí</mo><mo stretchy=false form=prefix>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo stretchy=false form=postfix>]</mo></mrow><annotation encoding=application/x-tex>C\colon [0,1]^d \to [0,1]</annotation></semantics></math> is a copula associated to <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>H</mi><annotation encoding=application/x-tex>H</annotation></semantics></math>. Conversely, any combination of a copula <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>C</mi><annotation encoding=application/x-tex>C</annotation></semantics></math> and margins <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>F</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>F_1,...,F_d</annotation></semantics></math> in the above way yields a valid <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>d</mi><annotation encoding=application/x-tex>d</annotation></semantics></math>-dimensional distribution function. Copulas themselves simply are multivariate distribution functions with standard uniform margins representing possible dependence structures. The margins <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>F</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>F</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>F_1,\dots,F_d</annotation></semantics></math> are then used to stretch the uniform margins of the copula to the appropriate domain.<br>Copulas greatly impact my approach to multivariate statistics and touch most of my research projects. Some past projects where copulas were the main objects under study (as opposed to useful tools) are the following: Instead of directly defining copulas, the research project <a href=#paper_6>Index-mixed copulas</a>¬†explores how new copulas can be build from initial ones. While using copula based models in non-parametric estimation of time series models is explored in <a href=#inCollection_1>Flexible and Dynamic Modeling of Dependencies via Copulas</a>, the article <a href=#paper_5>Smoothed bootstrapping of copula functionals</a>¬†discusses re-sampling procedures for functionals directly related to the underlying dependence structure.</span></p><button onclick=buttonCopula() id=buttonCopula class=readMoreButton>Read more</button></div><h2>Risk Measures for Multivariate Scenarios</h2><div class=researchInterestBlock><p>A common situation for banks, insurance companies or financial institutions is the need to quantitatively asses the risk inherent in their positions and portfolios. This is necessary due to regulatory requirements, but also for the internal reporting. Fameously starting with the value-at-risk, risk measures are constructed for this purpose and continue to be an active research area. Given that different risks are rarely independent, it is also valuable to study risk measures when considering multiple risks at the same time<span id=dotsRM>...</span><span class=readMore id=moreRM>.<br>In case of multiple risks, there are two main ways to approach the problem. In some situations, it is possible or even favourable to aggregate risks. For example, when considering a portfolio, the total value is the sum of the individual share prices <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>X</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>X_1,\dots,X_d</annotation></semantics></math> weighted by their percentage contributions, <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>w</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>w_1,\dots,w_d</annotation></semantics></math>, <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></msubsup><msub><mi>w</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding=application/x-tex>\sum_{i=1}^{d}w_i = 1</annotation></semantics></math>, Consequently, the total portfolio value is <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>S</mi><mo>=</mo><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></msubsup><msub><mi>w</mi><mi>i</mi></msub><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>S = \sum_{i=1}^{d} w_i X_i</annotation></semantics></math>. A univariate risk measure <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>œÅ</mi><annotation encoding=application/x-tex>\rho</annotation></semantics></math> can now be used to quantify the risk inherent in <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>S</mi><annotation encoding=application/x-tex>S</annotation></semantics></math> via <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>œÅ</mi><mo stretchy=false form=prefix>(</mo><mi>S</mi><mo stretchy=false form=postfix>)</mo><mo>=</mo><mi>œÅ</mi><mrow><mo stretchy=true form=prefix>(</mo><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>d</mi></munderover><msub><mi>w</mi><mi>i</mi></msub><msub><mi>X</mi><mi>i</mi></msub><mo stretchy=true form=postfix>)</mo></mrow><mi>.</mi></mrow><annotation encoding=application/x-tex>\rho(S) = \rho\left(\sum_{i=1}^{d} w_i X_i\right).</annotation></semantics></math> Popular univariate risk measures are for example the value- and tail-value-at-risk, expectiles or extremiles.<br>Properties of univariate risk measures and their application to optimal portfolio selection is one of my ongoing research subjects. Distributional properties of <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>S</mi><annotation encoding=application/x-tex>S</annotation></semantics></math> under arbitrary dependence structures are studied in <a href=#paper_1>On the distribution of sums of random variables with copula-induced dependence</a>, while optimal portfolio choice, that is the optimal choice of the weights <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>w</mi><mi>d</mi></msub></mrow><annotation encoding=application/x-tex>w_1,\dots,w_d</annotation></semantics></math>, is further discussed in <a href=#paper_3>Optimal Expected-Shortfall Portfolio Selection With Copula-Induced Dependence</a>. A unifying framework to study univariate risk measures is proposed in <a href=#paper_9>Generalized extremiles and risk measures of distorted random variables</a>.<br>When aggregation is not an option, risk measures are defined taking in random vectors as arguments. A multivariate risk measure is therefore a function <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>œÅ</mi><mo>:</mo><msup><mstyle mathvariant=double-struck><mi>‚Ñù</mi></mstyle><mi>d</mi></msup><mo>‚Üí</mo><mstyle mathvariant=script><mi>ùí≥</mi></mstyle><mo>,</mo></mrow><annotation encoding=application/x-tex>\rho \colon \mathbb{R}^d \to \mathcal{X},</annotation></semantics></math> where different domains <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mstyle mathvariant=script><mi>ùí≥</mi></mstyle><annotation encoding=application/x-tex>\mathcal{X}</annotation></semantics></math> for <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>œÅ</mi><mo stretchy=false form=prefix>(</mo><mstyle mathvariant=bold><mi>ùêó</mi></mstyle><mo stretchy=false form=postfix>)</mo></mrow><annotation encoding=application/x-tex>\rho(\mathbf{X})</annotation></semantics></math> are possible. For the generalized expectiles and tail-value-at-risk discussed in <a href=#paper_2>Multivariate geometric expectiles</a>¬†and <a href=#paper_4>Multivariate geometric tail- and range-value-at-risk</a>¬†we have <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mi>œÅ</mi><mo stretchy=false form=prefix>(</mo><mstyle mathvariant=bold><mi>ùêó</mi></mstyle><mo stretchy=false form=postfix>)</mo><mo>‚àà</mo><msup><mstyle mathvariant=double-struck><mi>‚Ñù</mi></mstyle><mi>d</mi></msup></mrow><annotation encoding=application/x-tex>\rho(\mathbf{X})\in\mathbb{R}^d</annotation></semantics></math>, but level-sets of the joint distribution function and their boundary are other popular choices.</span></p><button onclick=buttonRM() id=buttonRM class=readMoreButton>Read more</button></div><h2>Extreme Value Theory</h2><div class=researchInterestBlock><p>At first glance, statistics seems to provide tools to analyze typical outcomes such as averages or medians. There are however a number of situations where central tendencies are not of interest: the average water level is of little help when designing counter measures against flooding; typical day-to-day losses provide limited information for insurance and financial institutions when putting reserves into place that should protect in case of worst-case scenarios; or average lifetimes are not of interest when studying maximum lifetimes. Luckily, statisticians have developed tools to analyze the behaviour of the maximum of random outcomes starting at least in the 1920's. The approach is indeed similar to the central limit theorem used for averages<span id=dotsEVT>...</span><span class=readMore id=moreEVT>.<br>Starting with the familiar case of the central limit theorem for iid data, we can under a finite second moment condition find sequences of constants <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>=</mo><mi>œÉ</mi><mi>/</mi><msqrt><mi>n</mi></msqrt></mrow><annotation encoding=application/x-tex>a_n = \sigma/\sqrt{n}</annotation></semantics></math> and <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>b</mi><mi>n</mi></msub><mo>=</mo><mstyle mathvariant=double-struck><mi>ùîº</mi></mstyle><mo stretchy=false form=prefix>[</mo><mi>X</mi><mo stretchy=false form=postfix>]</mo></mrow><annotation encoding=application/x-tex>b_n = \mathbb{E}[X]</annotation></semantics></math> to arrive at a limiting distribution <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><munder><mo>lim</mo><mrow><mi>n</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow></munder><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mrow><mo stretchy=true form=prefix>(</mo><mfrac><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>X</mi><mi>i</mi></msub><mo>‚àí</mo><msub><mi>b</mi><mi>n</mi></msub></mrow><msub><mi>a</mi><mi>n</mi></msub></mfrac><mo>‚â§</mo><mi>x</mi><mo stretchy=true form=postfix>)</mo></mrow><mo>=</mo><mi>Œ¶</mi><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>,</mo></mrow><annotation encoding=application/x-tex>\lim_{n\to\infty}\mathbb{P}\left(\frac{\frac{1}{n}\sum_{i=1}^{n}X_i-b_n}{a_n} \leq x\right) = \Phi(x),</annotation></semantics></math> where <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>Œ¶</mi><annotation encoding=application/x-tex>\Phi</annotation></semantics></math> is the standard normal distribution. The result is exceptional due to the universal form of the limiting distribution. The stabilization of <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\frac{1}{n}\sum_{i=1}^{n}X_i</annotation></semantics></math> with <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><msub><mi>a</mi><mi>n</mi></msub><annotation encoding=application/x-tex>a_n</annotation></semantics></math> and <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><msub><mi>b</mi><mi>n</mi></msub><annotation encoding=application/x-tex>b_n</annotation></semantics></math> is necessary, since by itself <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\frac{1}{n}\sum_{i=1}^{n}X_i</annotation></semantics></math> converges almost surely to the constant <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mstyle mathvariant=double-struck><mi>ùîº</mi></mstyle><mo stretchy=false form=prefix>[</mo><mi>X</mi><mo stretchy=false form=postfix>]</mo></mrow><annotation encoding=application/x-tex>\mathbb{E}[X]</annotation></semantics></math>, which is of no help in a more detailed probabilistic analysis of the behavior of <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><msubsup><mo>‚àë</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup><msub><mi>X</mi><mi>i</mi></msub></mrow><annotation encoding=application/x-tex>\frac{1}{n}\sum_{i=1}^{n}X_i</annotation></semantics></math>.<br>While the central limit theorem allows to draw probabilistic conclusions concerning the empirical average, a similar situation presents itself when considering the sample maximum <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>M</mi><mi>n</mi></msub><mo>:=</mo><mo>max</mo><mo stretchy=false form=prefix>(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy=false form=postfix>)</mo></mrow><annotation encoding=application/x-tex>M_n := \max(X_1,...,X_n)</annotation></semantics></math>. Without any stabilization, <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><msub><mi>M</mi><mi>n</mi></msub><annotation encoding=application/x-tex>M_n</annotation></semantics></math> almost surely converges to the upper endpoint <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><msub><mi>F</mi><mo>+</mo></msub><annotation encoding=application/x-tex>F_{+}</annotation></semantics></math> of the common distribution function <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>F</mi><annotation encoding=application/x-tex>F</annotation></semantics></math>. Considering random variables <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mstyle mathvariant=bold><mi>ùêó</mi></mstyle><mo>=</mo><mo stretchy=false form=prefix>(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>X</mi><mi>n</mi></msub><mo stretchy=false form=postfix>)</mo></mrow><annotation encoding=application/x-tex>\mathbf{X}= (X_1,\dots,X_n)</annotation></semantics></math> with joint distribution <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>H</mi><annotation encoding=application/x-tex>H</annotation></semantics></math> and margins <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><msub><mi>F</mi><mi>i</mi></msub><annotation encoding=application/x-tex>F_i</annotation></semantics></math>, the relatively straight forward yet key insight to think about extremes probabilisticly is <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mo stretchy=false form=prefix>(</mo><msub><mi>M</mi><mi>n</mi></msub><mo>‚â§</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>=</mo><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mo stretchy=false form=prefix>(</mo><msub><mi>X</mi><mn>1</mn></msub><mo>‚â§</mo><mi>x</mi><mo>,</mo><mi>‚Ä¶</mi><mo>,</mo><msub><mi>X</mi><mi>d</mi></msub><mo>‚â§</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>=</mo><mi>H</mi><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>=</mo><mi>C</mi><mo stretchy=false form=prefix>(</mo><msub><mi>F</mi><mn>1</mn></msub><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>,</mo><mi>.</mi><mi>.</mi><mi>.</mi><mo>,</mo><msub><mi>F</mi><mi>d</mi></msub><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo stretchy=false form=postfix>)</mo><mo>,</mo></mrow><annotation encoding=application/x-tex>\mathbb{P}(M_n \leq x) = \mathbb{P}(X_1\leq x,\dots,X_d\leq x) = H(x,...,x) = C(F_1(x),...,F_d(x)),</annotation></semantics></math> where <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>C</mi><annotation encoding=application/x-tex>C</annotation></semantics></math> is a copula associated to <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>H</mi><annotation encoding=application/x-tex>H</annotation></semantics></math>. In the iid case this yields the classical starting point <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mo stretchy=false form=prefix>(</mo><msub><mi>M</mi><mi>n</mi></msub><mo>‚â§</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mo>=</mo><msup><mi>F</mi><mi>n</mi></msup><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo><mi>.</mi></mrow><annotation encoding=application/x-tex>\mathbb{P}(M_n \leq x) = F^n(x).</annotation></semantics></math> In case of iid data, the Fisher-Tippett-Gnedenko theorem now guarantees that if stabilizing constants <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><msub><mi>a</mi><mi>n</mi></msub><mo>></mo><mn>0</mn></mrow><annotation encoding=application/x-tex>a_n>0</annotation></semantics></math> and <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><msub><mi>b</mi><mi>n</mi></msub><annotation encoding=application/x-tex>b_n</annotation></semantics></math> are found such that <math display=block xmlns=http://www.w3.org/1998/Math/MathML><semantics><mrow><munder><mo>lim</mo><mrow><mi>n</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow></munder><mstyle mathvariant=double-struck><mi>‚Ñô</mi></mstyle><mrow><mo stretchy=true form=prefix>(</mo><mfrac><mrow><msub><mi>M</mi><mi>n</mi></msub><mo>‚àí</mo><msub><mi>b</mi><mi>n</mi></msub></mrow><msub><mi>a</mi><mi>n</mi></msub></mfrac><mo>‚â§</mo><mi>x</mi><mo stretchy=true form=postfix>)</mo></mrow><mo>=</mo><munder><mo>lim</mo><mrow><mi>n</mi><mo>‚Üí</mo><mi>‚àû</mi></mrow></munder><msup><mi>F</mi><mi>n</mi></msup><mo stretchy=false form=prefix>(</mo><msub><mi>a</mi><mi>n</mi></msub><mi>x</mi><mo>+</mo><msub><mi>b</mi><mi>n</mi></msub><mo stretchy=false form=postfix>)</mo><mo>=</mo><mi>G</mi><mo stretchy=false form=prefix>(</mo><mi>x</mi><mo stretchy=false form=postfix>)</mo></mrow><annotation encoding=application/x-tex>\lim_{n\to\infty}\mathbb{P}\left(\frac{M_n-b_n}{a_n} \leq x\right) = \lim_{n\to\infty}F^n(a_n x + b_n) = G(x)</annotation></semantics></math> for some non-degenerate distribution function <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>G</mi><annotation encoding=application/x-tex>G</annotation></semantics></math>, then <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>G</mi><annotation encoding=application/x-tex>G</annotation></semantics></math> belongs to the class of generalized extreme value (GEV) distributions. This allows for similar refined analysis as in the case of the central limit theorem, only the standard normal distribution <math display=inline xmlns=http://www.w3.org/1998/Math/MathML><semantics><mi>Œ¶</mi><annotation encoding=application/x-tex>\Phi</annotation></semantics></math> is now replaced by a GEV distribution. Different from the situation in the CLT, the GEV class of distributions crucially depends on a parameter that does not vanish in the limit and hence needs to be estimated. An overview to this problematic can for example for example be found in <a href=#inCollection_2>Estimation of the Extreme Value Index</a>, while <a href=#inCollection_3>Hunting for Black Swans in the European Banking Sector Using Extreme Value Analysis</a>¬†gives an impression of how extreme value theory can be used.<br>Part of my research interests is to study the highlighted type of problems for dependent data. As it turns out, even for dependent data Fisher-Tippett-Gnedenko type theorems can be established and stabilizing constants from the iid case (if they are known) can be used to stabilize the maximum under dependence as discussed in <a href=#paper_7>Limiting behavior of maxima under dependence</a>.</span></p><button onclick=buttonEVT() id=buttonEVT class=readMoreButton>Read more</button></div></section><section class=type2><div class=wave><svg id=wavePublications class="svg-2 hidden"data-name="Layer 1"xmlns=http://www.w3.org/2000/svg viewBox="0 0 1200 120"preserveAspectRatio=none><path id=wavePublicationsPath d="M0 120 V0 Q 1200 0 1200 0 V120 z"class=shape-fill-type2></path></svg></div><h1 id=publications>Publications</h1><p class=hidden><h2>Articles</h2><ol class=journalArticles><li id=paper_9 value=9><span class=journalArticle><span class=articleNames>Debrauwer, D., Gijbels, I., Herrmann, K.</span> <span class=articleDate>(2024)</span>. <span class=articleTitle>Generalized extremiles and risk measures of distorted random variables.</span><span class=articleSubmittedTo> Submitted to Electronic Journal of Statistics,</span> <span class=articlePages>1--58</span>.<a class=pubURL href=https://arxiv.org/abs/2405.11248>https://arxiv.org/abs/2405.11248</a></span><li id=paper_8 value=8><span class=journalArticle><span class=articleNames>Camirand Lemyre, F., L√©vesque, S., Domingue, M.P., Herrmann, K., Ethier, J.F.</span> <span class=articleDate>(2024)</span>. <span class=articleTitle>Distributed Statistical Analyses: A Scoping Review and Examples of Operational Frameworks Adapted to Healthcare.</span> <span class=articleJournal>JMIR Medical Informatics</span>, <span class=articleVolume></span>, <span class=articlePages>1--44</span>.<a class=pubURL href=https://www.medrxiv.org/content/10.1101/2023.12.21.23300389v1>https://www.medrxiv.org/content/10.1101/2023.12.21.23300389v1</a></span><li id=paper_7 value=7><span class=journalArticle><span class=articleNames>Herrmann, K., Hofert, M., Ne≈°lehov√°, J.G.</span> <span class=articleDate>(2024)</span>. <span class=articleTitle>Limiting behavior of maxima under dependence.</span><span class=articleSubmittedTo> Submitted to Annals of Statistics,</span> <span class=articlePages>1--45</span>.<a class=pubURL href=https://arxiv.org/abs/2405.02833>https://arxiv.org/abs/2405.02833</a></span><li id=paper_6 value=6><span class=journalArticle><span class=articleNames>Herrmann, K., Hofert, M., Sadr, N.</span> <span class=articleDate>(2023)</span>. <span class=articleTitle>Index-mixed copulas.</span><span class=articleSubmittedTo> Submitted to Annals of applied probability,</span> <span class=articlePages>1--46</span>.<a class=pubURL href=https://arxiv.org/abs/2306.10663>https://arxiv.org/abs/2306.10663</a></span><li id=paper_5 value=5><span class=journalArticle><span class=articleNames>Coblenz, M., Grothe, O., Herrmann, K., Hofert, M.</span> <span class=articleDate>(2022)</span>. <span class=articleTitle>Smoothed bootstrapping of copula functionals.</span> <span class=articleJournal>Electronic Journal of Statistics</span>, <span class=articleVolume>16</span><span class=articleNumber>(1)</span>, <span class=articlePages>2550--2606</span>.<a class=pubURL href=https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-16/issue-1/Smooth-bootstrapping-of-copula-functionals/10.1214/22-EJS2007.full>https://projecteuclid.org/journals/electronic-journal-of-statistics/volume-16/issue-1/Smooth-bootstrapping-of-copula-functionals/10.1214/22-EJS2007.full</a><a class=pubURLOpen href=https://arxiv.org/abs/2110.03397>https://arxiv.org/abs/2110.03397</a></span><li id=paper_4 value=4><span class=journalArticle><span class=articleNames>Herrmann, K., Hofert, M., Mailhot, M.</span> <span class=articleDate>(2019)</span>. <span class=articleTitle>Multivariate geometric tail- and range-value-at-risk.</span> <span class=articleJournal>ASTIN Bulletin: The Journal of the IAA</span>, <span class=articleVolume>50</span><span class=articleNumber>(1)</span>, <span class=articlePages>265--292</span>.<a class=pubURL href=https://www.cambridge.org/core/journals/astin-bulletin-journal-of-the-iaa/article/abs/multivariate-geometric-tail-and-rangevalueatrisk/984ABA7270A7365FA98DF11F26247452>https://www.cambridge.org/core/journals/astin-bulletin-journal-of-the-iaa/article/abs/multivariate-geometric-tail-and-rangevalueatrisk/984ABA7270A7365FA98DF11F26247452</a></span><li id=paper_3 value=3><span class=journalArticle><span class=articleNames>Gijbels, I., Herrmann, K.</span> <span class=articleDate>(2018)</span>. <span class=articleTitle>Optimal Expected-Shortfall Portfolio Selection With Copula-Induced Dependence.</span> <span class=articleJournal>Applied Mathematical Finance</span>, <span class=articleVolume>25</span><span class=articleNumber>(1)</span>, <span class=articlePages>66--106</span>.<a class=pubURL href=https://www.tandfonline.com/doi/full/10.1080/1350486X.2018.1492347>https://www.tandfonline.com/doi/full/10.1080/1350486X.2018.1492347</a></span><li id=paper_2 value=2><span class=journalArticle><span class=articleNames>Herrmann, K., Hofert, M., Mailhot, M.</span> <span class=articleDate>(2018)</span>. <span class=articleTitle>Multivariate geometric expectiles.</span> <span class=articleJournal>Scandinavian Actuarial Journal</span>, <span class=articleVolume>2018</span><span class=articleNumber>(7)</span>, <span class=articlePages>629--659</span>.<a class=pubURL href=https://www.tandfonline.com/doi/full/10.1080/03461238.2018.1426038>https://www.tandfonline.com/doi/full/10.1080/03461238.2018.1426038</a><a class=pubURLOpen href=https://arxiv.org/abs/1704.01503>https://arxiv.org/abs/1704.01503</a></span><li id=paper_1 value=1><span class=journalArticle><span class=articleNames>Gijbels, I., Herrmann, K.</span> <span class=articleDate>(2014)</span>. <span class=articleTitle>On the distribution of sums of random variables with copula-induced dependence.</span> <span class=articleJournal>Insurance: Mathematics and Economics</span>, <span class=articleVolume>59</span>, <span class=articlePages>27--44</span>.<a class=pubURL href=https://www.sciencedirect.com/science/article/pii/S0167668714000961>https://www.sciencedirect.com/science/article/pii/S0167668714000961</a></span></ol><h2>Book Chapters</h2><ol class=bookChapters><li id=inCollection_3 value=3><span class=bookChapter>Beirlant, J., Schoutens, W., De Spiegeleer, J., Reynkens, T., Herrmann, K. (2016). <span class=inCollectionTitle>Hunting for Black Swans in the European Banking Sector Using Extreme Value Analysis.</span> In: Kallsen, J., Papapantoleon, A. (eds) <span class=inCollectionBookTitle>Advanced Modelling in Mathematical Finance: In Honour of Ernst Eberlein</span>. Springer Proceedings in Mathematics & Statistics, vol 189, Springer, Cham, 147--166.<a class=pubURL href=https://link.springer.com/chapter/10.1007/978-3-319-45875-5_7>https://link.springer.com/chapter/10.1007/978-3-319-45875-5_7</a></span><li id=inCollection_2 value=2><span class=bookChapter>Beirlant, J., Herrmann, K., Teugels, J.L. (2016). <span class=inCollectionTitle>Estimation of the Extreme Value Index.</span> In: Longin, F. (ed) <span class=inCollectionBookTitle>Extreme Events in Finance: A Handbook of Extreme Value Theory and its Applications</span>. Springer Proceedings in Mathematics & StatisticsJohn Wiley & Sons, Inc., 97--115.<a class=pubURL href=https://extreme-events-finance.net/wiley-handbook/contributions/beirlant-herrmann-teugels-estimation-extreme-value-index/ >https://extreme-events-finance.net/wiley-handbook/contributions/beirlant-herrmann-teugels-estimation-extreme-value-index/</a></span><li id=inCollection_1 value=1><span class=bookChapter>Gijbels, I., Herrmann, K., Sznajder, D. (2015). <span class=inCollectionTitle>Flexible and Dynamic Modeling of Dependencies via Copulas.</span> In: Antoniadis, A., Poggi, J.M., Brossat, X. (eds) <span class=inCollectionBookTitle>Modeling and Stochastic Learning for Forecasting in High Dimensions</span>. , vol 217, Springer, 117--146.<a class=pubURL href=https://link.springer.com/chapter/10.1007/978-3-319-18732-7_7>https://link.springer.com/chapter/10.1007/978-3-319-18732-7_7</a></span></ol><h2>Other</h2><ol class=otherPublications><li id=other_2 value=2><span class=otherPublication>Herrmann, K. (2020). <span class=otherTitle>Conference report of the 2019 CRM-SSC address 'Tales of tails, tiles and ties in dependence modeling' by Johanna Ne≈°lehov√°.</span> <span class=otherOutlet>Bulletin of the Centre de recherches math√©matiques</span>, vol 26 issue 1. 14--14.<a class=pubURL href=http://www.crm.umontreal.ca/rapports/bulletin/bulletin26-1.pdf>http://www.crm.umontreal.ca/rapports/bulletin/bulletin26-1.pdf</a></span><li id=other_1 value=1><span class=otherPublication>Gijbels, I., Herrmann, K., Verhasselt, A. (2013). <span class=otherTitle>Discussion on 'Large covariance estimation by thresholding principal orthogonal components'.</span> <span class=otherOutlet>Journal of the Royal Statistical Society, Series B</span>, vol 75 issue 4. Wiley-Blackwell, 662--663.<a class=pubURL href=https://academic.oup.com/jrsssb/article/75/4/603/7075932>https://academic.oup.com/jrsssb/article/75/4/603/7075932</a></span></ol><p></section><section class=type1><div class=wave><svg id=waveTalks class="svg-2 hidden"data-name="Layer 1"xmlns=http://www.w3.org/2000/svg viewBox="0 0 1200 120"preserveAspectRatio=none><path id=waveTalksPath d="M0 120 V0 Q 1200 0 1200 0 V120 z"class=shape-fill-type1></path></svg></div><h1 id=talks>Talks</h1><p class=hidden><h2>Upcoming</h2><ol class=talks><li value=34><span class=talk><span class=title>TBA</span> <span class=invited>(invited talk)</span>. <span class=event>Young Talents in Actuarial Science and Quantitative Finance</span>, <span class=date>24 April 2025</span>, <span class=location>Waterloo, Canada.</span></span></ol><h2>Past</h2><ol class=talks><li value=33><span class=talk><span class=title>Distortions of multivariate GEV distributions and implications for risk management</span> <span class=invited>(invited talk)</span>. <span class=event>Bernoulli-ims 11th World Congress in Probability and Statistics</span>, <span class=date>12 August 2024</span>, <span class=location>Bochum, Germany.</span><a href=https://www.bernoulli-ims-worldcongress2024.org/ >https://www.bernoulli-ims-worldcongress2024.org/</a></span><li value=32><span class=talk><span class=title>Sur une classe de distorsions qui transforment les lois max-stables en lois max-stables</span> <span class=invited>(invited talk)</span>. <span class=event>Rencontres Scientifiques Montpellier Sherbrooke</span>, <span class=date>20 June 2024</span>, <span class=location>Sherbrooke, Canada.</span></span><li value=31><span class=talk><span class=title>Transformations of stable tail dependence functions</span>. <span class=event>2024 annual meeting of the Statistical Society of Canada</span>, <span class=date>04 June 2024</span>, <span class=location>St. John's, Canada.</span><a href=https://ssc.ca/en/meetings/annual/2024-ssc-annual-meeting-st-johns>https://ssc.ca/en/meetings/annual/2024-ssc-annual-meeting-st-johns</a></span><li value=30><span class=talk><span class=title>Distortions of stable tail dependence functions and their impact on multivariate risk measures</span>. <span class=event>7th Ontario-Qu√©bec Workshop in Insurance Mathematics</span>, <span class=date>08 March 2024</span>, <span class=location>Montreal, Canada.</span><a href=https://wim2024.weebly.com/ >https://wim2024.weebly.com/</a></span><li value=29><span class=talk><span class=title>Morillas type transformations of stable tail dependence functions</span>. <span class=event>CMStatistics 2023</span>, <span class=date>17 December 2023</span>, <span class=location>Berlin, Germany.</span><a href=https://www.cmstatistics.org/CMStatistics2023/programme.php>https://www.cmstatistics.org/CMStatistics2023/programme.php</a></span><li value=28><span class=talk><span class=title>On a class of distortions that transform GEV distributions into GEV distributions</span>. <span class=event>2023 annual meeting of the Statistical Society of Canada</span>, <span class=date>31 May 2023</span>, <span class=location>Ottawa, Canada.</span><a href=https://ssc.ca/en/meetings/annual/2023-ssc-annual-meeting-ottawa>https://ssc.ca/en/meetings/annual/2023-ssc-annual-meeting-ottawa</a></span><li value=27><span class=talk><span class=title>LaTeX Avanc√©</span>. <span class=event>Atelier LaTeX de CaMUS</span>, <span class=date>23 February 2023</span>, <span class=location>Sherbrooke, Canada.</span> <span class=misc>Presentation aimed at graduate students.</span></span><li value=26><span class=talk><span class=title>Copula diagonals, distortions and the asymptotic distribution of maxima</span> <span class=invited>(invited talk)</span>. <span class=event>2022 annual meeting of the Statistical Society of Canada</span>, <span class=date>01 June 2022</span>. <span class=misc>Online conference due to COVID-19 pandemic.</span><a href=https://ssc.ca/en/meetings/annual/2022-annual-meeting>https://ssc.ca/en/meetings/annual/2022-annual-meeting</a></span><li value=25><span class=talk><span class=title>Copula diagonals, distortions and the asymptotic distribution of maxima</span> <span class=invited>(invited talk)</span>. <span class=event>2022 Optimization Days</span>, <span class=date>16 May 2022</span>, <span class=location>Montreal, Canada.</span><a href=https://symposia.gerad.ca/jopt2022/en>https://symposia.gerad.ca/jopt2022/en</a></span><li value=24><span class=talk><span class=title>Extendible dependence structures and their impact on extremes of random vectors</span> <span class=invited>(invited talk)</span>. <span class=event>Symposium on Risk Modelling ‚Äì SRM21</span>, <span class=date>26 November 2021</span>. <span class=misc>Online conference due to COVID-19 pandemic.</span><a href=https://ssc.ca/en/publications/ssc-liaison/vol-35-5-october-2021/symposium-risk-modelling>https://ssc.ca/en/publications/ssc-liaison/vol-35-5-october-2021/symposium-risk-modelling</a></span><li value=23><span class=talk><span class=title>Smooth bootstrapping of copula functionals</span> <span class=invited>(invited talk)</span>. <span class=event>International Symposium on Nonparametric Statistics (ISNPS2020)</span>, <span class=location>Paphos, Cyprus.</span> <span class=misc>Unable to deliver, meeting canceled due to COVID-19 outbreak.</span><a href=https://www.isnps.org/conferences.html>https://www.isnps.org/conferences.html</a></span><li value=22><span class=talk><span class=title>Measuring risk of multivariate extreme outcomes under Archimedean dependence</span> <span class=invited>(invited talk)</span>. <span class=event>2020 annual meeting of the Statistical Society of Canada</span>, <span class=location>Ottawa, Canada.</span> <span class=misc>Unable to deliver, meeting canceled due to COVID-19 outbreak.</span><a href=https://ssc.ca/en/meetings/annual/2020-annual-meeting>https://ssc.ca/en/meetings/annual/2020-annual-meeting</a></span><li value=21><span class=talk><span class=title>Univariate and multivariate extremes of extendible random vectors</span> <span class=invited>(invited talk)</span>. <span class=event>KU Leuven joint statistics seminar series</span>, <span class=date>19 December 2019</span>, <span class=location>Leuven, Belgium.</span><a href=https://wis.kuleuven.be/agenda/sem-joint-stat/joint-statistics-seminar-2019-2020>https://wis.kuleuven.be/agenda/sem-joint-stat/joint-statistics-seminar-2019-2020</a></span><li value=20><span class=talk><span class=title>Smooth bootstrapping of copula functionals</span>. <span class=event>CMStatistics 2019</span>, <span class=date>14 December 2019</span>, <span class=location>London, United Kingdom.</span><a href=https://www.cmstatistics.org/CMStatistics2019>https://www.cmstatistics.org/CMStatistics2019</a></span><li value=19><span class=talk><span class=title>Copula diagonals and extremes of extendible random vectors</span> <span class=invited>(invited talk)</span>. <span class=event>Quantact seminar Universit√© Laval</span>, <span class=date>29 November 2019</span>, <span class=location>Qu√©bec, Canada.</span><a href=http://quantact.uqam.ca/pages/seminaires.php>http://quantact.uqam.ca/pages/seminaires.php</a></span><li value=18><span class=talk><span class=title>Univariate and multivariate extremes of extendible random vectors</span> <span class=invited>(invited talk)</span>. <span class=event>McGill statistics seminar series</span>, <span class=date>18 October 2019</span>, <span class=location>Montr√©al, Canada.</span><a href=https://mcgillstat.github.io/post/2019fall/2019-10-18/ >https://mcgillstat.github.io/post/2019fall/2019-10-18/</a></span><li value=17><span class=talk><span class=title>The Extreme Value Limit Theorem for Dependent Sequences of Random Variables</span> <span class=invited>(invited talk)</span>. <span class=event>International Conference on Statistical Distributions and Applications (ICOSDA 2019)</span>, <span class=date>12 October 2019</span>, <span class=location>Grand Rapids, United States of America.</span><a href=https://people.se.cmich.edu/lee1c/icosda2019/ >https://people.se.cmich.edu/lee1c/icosda2019/</a></span><li value=16><span class=talk><span class=title>Smooth bootstrapping of copula functionals</span>. <span class=event>2019 annual meeting of the Statistical Society of Canada</span>, <span class=date>28 May 2019</span>, <span class=location>Calgary, Canada.</span><a href=https://ssc.ca/en/meeting/annual/2019>https://ssc.ca/en/meeting/annual/2019</a></span><li value=15><span class=talk><span class=title>Estimation multivari√©e par noyau: smoothed bootstrap et mesures de risque</span> <span class=invited>(invited talk)</span>. <span class=event>Universit√© de Sherbrooke</span>, <span class=date>18 December 2018</span>, <span class=location>Sherbrooke, Canada.</span></span><li value=14><span class=talk><span class=title>Multivariate Geometric Expectiles</span> <span class=invited>(invited talk)</span>. <span class=event>Karlsruhe Institute of Technology</span>, <span class=date>16 April 2018</span>, <span class=location>Karlsruhe, Germany.</span><a href=https://www.ior.kit.edu/Kolloquium.php>https://www.ior.kit.edu/Kolloquium.php</a></span><li value=13><span class=talk><span class=title>Multivariate Geometric Risk Measures</span>. <span class=event>Pizza Seminar at Concordia University</span>, <span class=date>16 March 2018</span>, <span class=location>Montr√©al, Canada.</span></span><li value=12><span class=talk><span class=title>Multivariate Geometric Expectiles</span> <span class=invited>(invited talk)</span>. <span class=event>Universit√© du Qu√©bec √† Montr√©al</span>, <span class=date>12 January 2018</span>, <span class=location>Montr√©al, Canada.</span></span><li value=11><span class=talk><span class=title>Multivariate Geometric Expectiles</span> <span class=invited>(invited talk)</span>. <span class=event>Universit√© de Sherbrooke</span>, <span class=date>20 April 2017</span>, <span class=location>Sherbrooke, Canada.</span></span><li value=10><span class=talk><span class=title>Sums of Copula Dependent Random Variables and Geometric Approximations to Integration Domains</span> <span class=invited>(invited talk)</span>. <span class=event>University of Waterloo</span>, <span class=date>23 March 2017</span>, <span class=location>Waterloo, Canada.</span></span><li value=9><span class=talk><span class=title>Geometric Approximations to Integration Domains and Numerical Algorithms for Distribution Functions</span> <span class=invited>(invited talk)</span>. <span class=event>Seminar Math√©matiques actuarielles et financi√®res</span>, <span class=date>17 February 2017</span>, <span class=location>Montr√©al, Canada.</span><a href=http://www.crm.umontreal.ca/cal/en/sem2017023.html>http://www.crm.umontreal.ca/cal/en/sem2017023.html</a></span><li value=8><span class=talk><span class=title>Using the Rosenblatt Transformation to Compute Joint Probabilities for Random Vectors</span> <span class=invited>(invited talk)</span>. <span class=event>CMStatistics 2016</span>, <span class=date>10 December 2016</span>, <span class=location>Seville, Spain.</span><a href=https://www.cmstatistics.org/CMStatistics2016/index.php>https://www.cmstatistics.org/CMStatistics2016/index.php</a></span><li value=7><span class=talk><span class=title>A Geometric Algorithm for Multivariate Normal Probabilities</span> <span class=invited>(invited talk)</span>. <span class=event>Flexible Statistical Modelling: Past, Present and Future (FSM2016)</span>, <span class=date>16 September 2016</span>, <span class=location>Gent, Belgium.</span></span><li value=6><span class=talk><span class=title>The impact of varying dependence structures on sums of random variables and implications for portfolio selection</span> <span class=invited>(invited talk)</span>. <span class=event>CMStatistics 2015</span>, <span class=date>14 December 2015</span>, <span class=location>London, United Kingdom.</span><a href=https://www.cmstatistics.org/CMStatistics2015/ >https://www.cmstatistics.org/CMStatistics2015/</a></span><li value=5><span class=talk><span class=title>Sums of dependent random variables and portfolio selection via copula modeling</span>. <span class=event>30th European Meeting of Statisticians</span>, <span class=date>08 July 2015</span>, <span class=location>Amsterdam, Netherlands.</span></span><li value=4><span class=talk><span class=title>Copulas, Sums of Dependent Random Variables and Portfolio Selection</span> <span class=invited>(invited talk)</span>. <span class=event>Talk at Risk Lab ETH Z√ºrich</span>, <span class=date>04 May 2015</span>, <span class=location>Z√ºrich, Switzerland.</span></span><li value=3><span class=talk><span class=title>Sums of dependent random variables and portfolio selection via copula modeling</span>. <span class=event>CMStatistics 2014</span>, <span class=date>08 December 2014</span>, <span class=location>Pisa, Italy.</span><a href=https://www.cmstatistics.org/ERCIM2014/CMStatistics.php>https://www.cmstatistics.org/ERCIM2014/CMStatistics.php</a></span><li value=2><span class=talk><span class=title>Studying the sum of two dependent random variables via copula modeling</span>. <span class=event>Model Selection, Nonparametrics and Dependence Modeling</span>, <span class=date>09 July 2013</span>, <span class=location>Rennes, France.</span></span><li value=1><span class=talk><span class=title>Portfolio Value-at-Risk and Expected-Shortfall in a Copula Setup</span>. <span class=event>20th Annual Conference of the Belgium Statistical Society</span>, <span class=date>25 October 2012</span>, <span class=location>Li√®ge, Belgium.</span></span></ol><h2>Poster Presentations</h2><ol class=talks><li value=2><b>Studying Sums of Dependent Random Variables via Copulas.</b> 25th Anniversary of LStat in Leuven, 13 December 2013, Leuven, Belgium.<li value=1><b>Portfolio Value-at-Risk and Expected-Shortfall in a Copula Setup.</b> Copulae in Mathematical and Quantitative Finance, 10 July 2012, Krakow, Poland.</ol><p></section><section class=type2><div class=wave><svg id=waveTeaching class="svg-1 hidden"data-name="Layer 1"xmlns=http://www.w3.org/2000/svg viewBox="0 0 1200 120"preserveAspectRatio=none><path id=waveTeachingPath d="M0 120 V0 Q 1200 0 1200 0 V120 z"class=shape-fill-type2></path></svg></div><h1 id=teaching>Teaching</h1><p class=hidden><h2>As instructor</h2><ol class=coursesAsInstructor><li value=17><span class=course>2024: <span class=title>STT438 Statistique computationnelle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=16><span class=course>2024: <span class=title>STT390 Statistique math√©matique et inf√©rentielle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=15><span class=course>2023: <span class=title>STT701 Probabilit√©s</span>, Graduate, Universit√© de Sherbrooke.</span><li value=14><span class=course>2023: <span class=title>STT438 Statistique computationnelle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=13><span class=course>2023: <span class=title>STT390 Statistique math√©matique et inf√©rentielle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=12><span class=course>2022: <span class=title>MAT712 Mesure et Int√©gration</span>, Graduate, Universit√© de Sherbrooke.</span><li value=11><span class=course>2022: <span class=title>STT438 Statistique computationnelle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=10><span class=course>2022: <span class=title>STT701 Probabilit√©s</span>, Graduate, Universit√© de Sherbrooke.</span><li value=9><span class=course>2022: <span class=title>STT390 Statistique math√©matique et inf√©rentielle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=8><span class=course>2021: <span class=title>STT438 Statistique computationnelle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=7><span class=course>2021: <span class=title>STT390 Statistique math√©matique et inf√©rentielle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=6><span class=course>2020: <span class=title>STT438 Statistique computationnelle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=5><span class=course>2020: <span class=title>STT701 Probabilit√©s</span>, Graduate, Universit√© de Sherbrooke.</span><li value=4><span class=course>2020: <span class=title>STT390 Statistique math√©matique et inf√©rentielle</span>, Undergraduate, Universit√© de Sherbrooke.</span><li value=3><span class=course>2018: <span class=title>STAT 287 Statistics Lab I</span>, Undergraduate, Concordia University.</span><li value=2><span class=course>2017: <span class=title>INTE 293 INTE 293 - Computer Application Development</span>, Undergraduate, Concordia University.</span><li value=1><span class=course>2016: <span class=title>INTE 293 INTE 293 - Computer Application Development</span>, Undergraduate, Concordia University.</span></ol><h2>As teaching assistant</h2><ol class=coursesAsAssistant><li value=7><span class=course>2015/2016: <span class=title>Statistical Inference</span>, Graduate, KU Leuven.</span><li value=6><span class=course>2015: <span class=title>Advanced Non-Parametric Statistics</span>, Graduate, KU Leuven.</span><li value=5><span class=course>2014/2015: <span class=title>Advanced Statistical Inference</span>, Graduate, KU Leuven.</span><li value=4><span class=course>2013/2014: <span class=title>Mathematical Statistics II</span>, Graduate, KU Leuven.</span><li value=3><span class=course>2013: <span class=title>Advanced Non-Parametric Statistics</span>, Graduate, KU Leuven.</span><li value=2><span class=course>2012/2013: <span class=title>Mathematical Statistics II</span>, Graduate, KU Leuven.</span><li value=1><span class=course>2011/2012: <span class=title>Mathematical Statistics II</span>, Graduate, KU Leuven.</span></ol><p></section><section class=type1><div class=wave><svg id=waveSoftware class="svg-2 hidden"data-name="Layer 1"xmlns=http://www.w3.org/2000/svg viewBox="0 0 1200 120"preserveAspectRatio=none><path id=waveSoftwarePath d="M0 120 V0 Q 1200 0 1200 0 V120 z"class=shape-fill-type1></path></svg></div><h1 id=software>Software</h1><div class=researchInterestBlock><p class=hidden>Generally, software that I have available can be found on my <a href=https://github.com/KlausHerrmann/ >github</a> page. Some of the (hopefully) more interesting projects are discussed below:</div><h2>multIntTestFunc</h2><div class=researchInterestBlock><p class=hidden>The R-package <a href="https://github.com/KlausHerrmann/multIntTestFunc?tab=readme-ov-file#multinttestfunc">multIntTestFunc</a> provides implementations of test functions for multivariate numerical integration that can be used to test multivariate integration routines. The package covers six different integration domains (unit hypercube, unit ball, unit sphere, standard simplex, non-negative real numbers and R^n). For each domain several functions with different properties (smooth, non-differentiable, ...) are available. The functions are available in all dimensions n >= 1. For each function the exact value of the integral is known and implemented to allow testing the accuracy of multivariate integration routines. The package is available on <a href=https://cran.r-project.org/web/packages/multIntTestFunc/index.html>CRAN</a> and <a href="https://github.com/KlausHerrmann/multIntTestFunc?tab=readme-ov-file#multinttestfunc">github</a>.</div><h2>khermiscLaTeX</h2><div class=researchInterestBlock><p class=hidden>I have compiled some of my usual LaTeX definitions into the <a href=https://github.com/KlausHerrmann/khermiscLaTeX>khermiscLaTeX</a> package. The package has two main features: First, it provides an accessible interface for commonly used symbols, and second (more importantly) it uses the xparse package to provide overloaded versions of commonly used functions.</div></section>
        
        
        <script src="https://giscus.app/client.js"
        data-repo="klausherrmann/blogcontent"
        data-repo-id="R_kgDONDGX4w"
        data-category="Announcements"
        data-category-id="DIC_kwDONDGX484CjiEk"
        data-mapping="pathname"
        data-strict="0"
        data-reactions-enabled="1"
        data-emit-metadata="0"
        data-input-position="bottom"
        data-theme="light"
        data-lang="en"
        crossorigin="anonymous"
        async>
</script>
      
        
        <footer><p>¬© Klaus Herrmann ‚Äî Last update: Sep/2024</footer>
